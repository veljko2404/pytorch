{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-17T00:59:02.495084Z",
     "start_time": "2026-01-17T00:59:02.490656Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet18\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T00:59:16.541374Z",
     "start_time": "2026-01-17T00:59:15.450606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)"
   ],
   "id": "2d805f18054b887a",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T01:03:35.091640Z",
     "start_time": "2026-01-17T01:03:35.083462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch=256):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, 1)\n",
    "        self.bn = nn.BatchNorm2d(out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.bn(self.conv(x))\n",
    "\n",
    "class SelfDistillResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        base = resnet18(pretrained=False)\n",
    "\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.layer1 = base.layer1 # 64\n",
    "        self.layer2 = base.layer2 # 128\n",
    "        self.layer3 = base.layer3 # 256\n",
    "        self.layer4 = base.layer4 # 512\n",
    "\n",
    "        # Bottlenecks\n",
    "        self.b1 = Bottleneck(64, 256)\n",
    "        self.b2 = Bottleneck(128, 256)\n",
    "        self.b3 = Bottleneck(256, 256)\n",
    "        self.b4 = Bottleneck(512, 256)\n",
    "\n",
    "        # Classifiers\n",
    "        self.fc1 = nn.Linear(256, num_classes)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "        self.fc4 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "\n",
    "        f1 = self.layer1(x)\n",
    "        h1 = self.b1(f1)\n",
    "        p1 = self.fc1(F.adaptive_avg_pool2d(h1,1).flatten(1))\n",
    "\n",
    "        f2 = self.layer2(f1)\n",
    "        h2 = self.b2(f2)\n",
    "        p2 = self.fc2(F.adaptive_avg_pool2d(h2,1).flatten(1))\n",
    "\n",
    "        f3 = self.layer3(f2)\n",
    "        h3 = self.b3(f3)\n",
    "        p3 = self.fc3(F.adaptive_avg_pool2d(h3,1).flatten(1))\n",
    "\n",
    "        f4 = self.layer4(f3)\n",
    "        h4 = self.b4(f4)\n",
    "        p4 = self.fc4(F.adaptive_avg_pool2d(h4,1).flatten(1))\n",
    "\n",
    "        return [p1, p2, p3, p4], [h1, h2, h3, h4]"
   ],
   "id": "dd15b5104457845c",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T01:03:38.892743Z",
     "start_time": "2026-01-17T01:03:38.860020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CE = nn.CrossEntropyLoss()\n",
    "KL = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "MSE = nn.MSELoss()\n",
    "\n",
    "T = 4.0\n",
    "alpha = 0.7\n",
    "beta = 0.3\n",
    "\n",
    "def train_step(model, images, labels, optimizer):\n",
    "    logits, feats = model(images)\n",
    "\n",
    "    teacher_logits = logits[-1]\n",
    "    teacher_feat = feats[-1].detach()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    for i in range(4):\n",
    "        student_logits = logits[i]\n",
    "        student_feat = feats[i]\n",
    "\n",
    "        loss_ce = CE(student_logits, labels)\n",
    "\n",
    "        if i == 3:\n",
    "            total_loss += loss_ce\n",
    "            continue\n",
    "\n",
    "        log_p = F.log_softmax(student_logits / T, dim=1)\n",
    "        q = F.softmax(teacher_logits / T, dim=1)\n",
    "        loss_kl = KL(log_p, q) * (T*T)\n",
    "\n",
    "        teacher_resized = F.interpolate(teacher_feat, size=student_feat.shape[2:], mode=\"bilinear\")\n",
    "        loss_l2 = MSE(student_feat, teacher_resized)\n",
    "\n",
    "        total_loss += loss_ce + alpha * loss_kl + beta * loss_l2\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return total_loss.item()"
   ],
   "id": "417be69991c361ca",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T01:08:47.264461Z",
     "start_time": "2026-01-17T01:03:41.605621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lr = 0.05\n",
    "epochs = 100\n",
    "model = SelfDistillResNet18().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    if epoch == 40 or epoch == 80:\n",
    "        lr /= 2\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        print(\"Learning rate changed to \", lr)\n",
    "\n",
    "    model.train()\n",
    "    for images, labels in trainloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        loss = train_step(model, images, labels, optimizer)\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            logits, _ = model(images)\n",
    "            final_outputs = logits[-1]\n",
    "            _, predicted = torch.max(final_outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    acc = 100 * correct / total\n",
    "\n",
    "    print(f\"Epoch {epoch} | Loss: {loss:.4f} | Accuracy: {acc:.2f}%\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nTotal training time: {total_time:.2f} seconds\")\n",
    "\n",
    "torch.save(model.state_dict(), \"pytorch/saved_models/cifar_10.pt\")\n",
    "print(\"Model saved as pytorch/saved_models/cifar_10.pt\")\n"
   ],
   "id": "5fc56553486d0278",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Veljko\\PycharmProjects\\pytorch\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Veljko\\PycharmProjects\\pytorch\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 9\u001B[39m\n\u001B[32m      7\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m images, labels \u001B[38;5;129;01min\u001B[39;00m trainloader:\n\u001B[32m      8\u001B[39m         images, labels = images.to(device), labels.to(device)\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m         loss = \u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     11\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m | Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     13\u001B[39m total_time = time.time() - start_time\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 37\u001B[39m, in \u001B[36mtrain_step\u001B[39m\u001B[34m(model, images, labels, optimizer)\u001B[39m\n\u001B[32m     34\u001B[39m     total_loss += loss_ce + alpha * loss_kl + beta * loss_l2\n\u001B[32m     36\u001B[39m optimizer.zero_grad()\n\u001B[32m---> \u001B[39m\u001B[32m37\u001B[39m \u001B[43mtotal_loss\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     38\u001B[39m optimizer.step()\n\u001B[32m     40\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m total_loss.item()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pytorch\\.venv\\Lib\\site-packages\\torch\\_tensor.py:625\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    615\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    616\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    617\u001B[39m         Tensor.backward,\n\u001B[32m    618\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    623\u001B[39m         inputs=inputs,\n\u001B[32m    624\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m625\u001B[39m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mautograd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    626\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs\u001B[49m\n\u001B[32m    627\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pytorch\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    349\u001B[39m     retain_graph = create_graph\n\u001B[32m    351\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    352\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    353\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m354\u001B[39m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    355\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    356\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    357\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    358\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    359\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs_tuple\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    360\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    361\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    362\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pytorch\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:841\u001B[39m, in \u001B[36m_engine_run_backward\u001B[39m\u001B[34m(t_outputs, *args, **kwargs)\u001B[39m\n\u001B[32m    839\u001B[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[32m    840\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m841\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_execution_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[32m    842\u001B[39m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    843\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    844\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    845\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
